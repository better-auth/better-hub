/**
 * Codegen script — fetches live pricing from the OpenRouter API and writes
 * `apps/web/src/lib/billing/openrouter-models.generated.ts`.
 *
 * Usage:
 *   pnpm generate:models          # generate / update the file
 *   pnpm generate:models:check    # exit 1 if the file would change (CI)
 */

import { readFileSync, writeFileSync, existsSync } from "node:fs";
import { execFileSync } from "node:child_process";
import { resolve, dirname } from "node:path";
import { fileURLToPath } from "node:url";

// ── Config ──────────────────────────────────────────────────────────────────

/**
 * Multiplier applied to OpenRouter's per-token cost.
 *
 * 100 = pass-through
 * 120 = +20%.
 */
const COST_MULTIPLIER = 140;

/**
 * Models we use through OpenRouter.
 * `id` must match OpenRouter's model id.
 */
const MANAGED_MODELS = [
	{
		id: "moonshotai/kimi-k2.5",
		label: "Kimi K2.5",
		desc: "Moonshot AI",
	},
	{
		id: "anthropic/claude-sonnet-4",
		label: "Claude Sonnet 4",
		desc: "Anthropic",
	},
	{
		id: "anthropic/claude-opus-4",
		label: "Claude Opus 4",
		desc: "Anthropic",
	},
	{
		id: "openai/gpt-4.1",
		label: "GPT-4.1",
		desc: "OpenAI",
	},
	{
		id: "openai/o3-mini",
		label: "o3-mini",
		desc: "OpenAI",
	},
	{
		id: "google/gemini-2.5-pro-preview",
		label: "Gemini 2.5 Pro",
		desc: "Google",
	},
	{
		id: "google/gemini-2.5-flash",
		label: "Gemini 2.5 Flash",
		desc: "Google",
	},
	{
		id: "deepseek/deepseek-chat-v3.1",
		label: "DeepSeek V3.1",
		desc: "DeepSeek",
	},
	{
		id: "meta-llama/llama-4-maverick",
		label: "Llama 4 Maverick",
		desc: "Meta",
	},
	{
		id: "anthropic/claude-haiku-4.5",
		label: "Claude Haiku",
		desc: "Anthropic",
	},
] as const;

// ── Paths ───────────────────────────────────────────────────────────────────

const __dirname = dirname(fileURLToPath(import.meta.url));
const OUT_PATH = resolve(__dirname, "../src/lib/billing/openrouter-models.generated.ts");

// ── Types ───────────────────────────────────────────────────────────────────

interface OpenRouterModel {
	id: string;
	pricing?: {
		prompt?: string;
		completion?: string;
		input_cache_read?: string;
		input_cache_write?: string;
	};
}

// ── Main ────────────────────────────────────────────────────────────────────

async function main() {
	const checkOnly = process.argv.includes("--check");
	const previous = existsSync(OUT_PATH) ? readFileSync(OUT_PATH, "utf-8") : null;

	if (checkOnly && previous === null) {
		console.error(
			"openrouter-models.generated.ts does not exist. Run pnpm generate:models.",
		);
		process.exit(1);
	}

	// 1. Fetch model list from OpenRouter
	console.log("Fetching models from OpenRouter…");
	const res = await fetch("https://openrouter.ai/api/v1/models");
	if (!res.ok) {
		throw new Error(`OpenRouter API responded with ${res.status}: ${res.statusText}`);
	}
	const { data } = (await res.json()) as { data: OpenRouterModel[] };

	// Build a lookup map keyed by model id
	const lookup = new Map<string, OpenRouterModel>();
	for (const m of data) {
		lookup.set(m.id, m);
	}

	// 2. Resolve pricing for each managed model
	const entries: string[] = [];
	const missing: string[] = [];

	for (const model of MANAGED_MODELS) {
		const remote = lookup.get(model.id);
		if (!remote?.pricing?.prompt || !remote?.pricing?.completion) {
			missing.push(model.id);
			continue;
		}

		const prompt = parseFloat(remote.pricing.prompt);
		const inputPerM = (prompt * 1_000_000 * COST_MULTIPLIER) / 100;
		const outputPerM =
			(parseFloat(remote.pricing.completion) * 1_000_000 * COST_MULTIPLIER) / 100;

		// Cache multipliers are ratios relative to input price — COST_MULTIPLIER cancels out
		const cacheRead = remote.pricing.input_cache_read
			? parseFloat(remote.pricing.input_cache_read) / prompt
			: undefined;
		const cacheWrite = remote.pricing.input_cache_write
			? parseFloat(remote.pricing.input_cache_write) / prompt
			: undefined;

		let pricingStr = `inputPerM: ${round(inputPerM)}, outputPerM: ${round(outputPerM)}`;
		if (cacheRead !== undefined)
			pricingStr += `, cacheReadMultiplier: ${round(cacheRead)}`;
		if (cacheWrite !== undefined)
			pricingStr += `, cacheWriteMultiplier: ${round(cacheWrite)}`;

		entries.push(
			[
				`\t"${model.id}": {`,
				`\t\tlabel: "${model.label}",`,
				`\t\tdesc: "${model.desc}",`,
				`\t\tpricing: { ${pricingStr} },`,
				`\t},`,
			].join("\n"),
		);
	}

	if (missing.length > 0) {
		throw new Error(
			`The following models were not found (or have no pricing) on OpenRouter:\n` +
				missing.map((id) => `  - ${id}`).join("\n") +
				`\nThey may have been deprecated — update MANAGED_MODELS in this script.`,
		);
	}

	// 3. Generate file content
	const content = [
		`// This file is auto-generated by apps/web/scripts/generate-openrouter-models.mts`,
		`// Do not edit manually — run: pnpm generate:models`,
		``,
		`import type { ModelDef } from "./ai-models";`,
		``,
		`export const OPENROUTER_MODELS = {`,
		entries.join("\n"),
		`} as const satisfies Record<string, ModelDef>;`,
		``,
	].join("\n");

	// 4. Format content via oxfmt (write to output path, then format in-place)
	writeFileSync(OUT_PATH, content, "utf-8");
	execFileSync("pnpm", ["oxfmt", "--write", OUT_PATH], { stdio: "ignore" });
	const formatted = readFileSync(OUT_PATH, "utf-8");

	// 5. Check mode — compare with previous content
	if (checkOnly) {
		if (previous === formatted) {
			console.log("Model pricing is up to date.");
		} else {
			// Restore original file
			if (previous !== null) writeFileSync(OUT_PATH, previous, "utf-8");
			console.error(
				"Model pricing is out of date. Run pnpm generate:models to update.",
			);
			process.exit(1);
		}
		return;
	}

	console.log(`Wrote ${OUT_PATH}`);
}

function round(n: number): number {
	// Round to at most 6 decimal places to avoid floating point noise
	return Math.round(n * 1_000_000) / 1_000_000;
}

main().catch((err) => {
	console.error(err);
	process.exit(1);
});
